{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install dask_jobqueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "import datetime\n",
    "from time import time\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightfm\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:36153</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>8.00 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:36153' processes=1 threads=1, memory=8.00 GiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set LOCAL to True for single-machine execution while developing\n",
    "# Set LOCAL to False for cluster execution\n",
    "LOCAL = True\n",
    "\n",
    "if LOCAL:\n",
    "    # This line creates a single-machine dask client\n",
    "    client = Client()\n",
    "else:    \n",
    "    # This line creates a SLURM cluster dask and dask client\n",
    "    # Logging outputs will be stored in /scratch/{your-netid}\n",
    "    \n",
    "    cluster = SLURMCluster(memory='4GB', cores=2, python='/scratch/work/public/dask/bin/python', \n",
    "                               local_directory='/tmp/{}/'.format(os.environ['SLURM_JOB_USER']),\n",
    "                               job_extra=['--output=/scratch/{}/slurm-%j.out'.format(os.environ['SLURM_JOB_USER'])])\n",
    "\n",
    "    cluster.submit_command = 'slurm'\n",
    "    cluster.scale(100)\n",
    "\n",
    "    display(cluster)\n",
    "    client = Client(cluster)\n",
    "\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and configure spark session\n",
    "spark = SparkSession.builder \\\n",
    "  .master(\"local\") \\\n",
    "  .appName(\"parquet_example\") \\\n",
    "  .config('spark.sql.execution.arrow.pyspark.enabled', True) \\\n",
    "  .config('spark.sql.session.timeZone', 'UTC') \\\n",
    "  .config('spark.driver.memory','32G') \\\n",
    "  .config('spark.ui.showConsoleProgress', True) \\\n",
    "  .config('spark.sql.repl.eagerEval.enabled', True) \\\n",
    "  .getOrCreate()\n",
    "\n",
    "# Enable Arrow-based columnar data\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from hdfs\n",
    "df_val = spark.read.parquet('/scratch/work/courses/DSGA1004-2021/MSD/cf_validation.parquet')\n",
    "df_test = spark.read.parquet('/scratch/work/courses/DSGA1004-2021/MSD/cf_test.parquet')\n",
    "df_train = spark.read.parquet('/scratch/work/courses/DSGA1004-2021/MSD/cf_train_new.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to interactions matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_train, df_test):\n",
    "    \n",
    "    '''\n",
    "        Params:\n",
    "            df: dataframe which contains 'user_id','track_id','count' columns\n",
    "            \n",
    "        Return: \n",
    "            interactions: \n",
    "            weights: \n",
    "    '''\n",
    "    total_item_user = pd.concat([df_train, df_test])\n",
    "    \n",
    "    data_obj = Dataset()\n",
    "    data_obj.fit(users=total_item_user['user_id'].unique(), items=total_item_user['track_id'].unique())\n",
    "    \n",
    "    interactions_train, weights_train = data_obj.build_interactions([(df_train['user_id'][i], df_train['track_id'][i], \\\n",
    "                                                                      df_train['count'][i]) for i in range(df_train.shape[0])])\n",
    "    interactions_test, weights_test = data_obj.build_interactions([(df_test['user_id'][i], \\\n",
    "                                                          df_test['track_id'][i], df_test['count'][i]) for i in range(df_test.shape[0])])\n",
    "        \n",
    "    return interactions_train, weights_train, interactions_test, weights_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightfm_train(train, rank, regParam, maxIter, model_type, weights):\n",
    "    \n",
    "    '''\n",
    "        Params:\n",
    "            train: training csr matrix in form of scipy.sparse.COOMatrix\n",
    "            rank: dimensionality of the feature latent embeddings\n",
    "            regParam: L2 penalty on user features\n",
    "            maxIter: number of epochs to run\n",
    "            model_type: 'warp' - Weighted Approximate-Rank Pairwise Loss \n",
    "                        'bpr' - Bayesian Personalised Ranking\n",
    "                         these 2 model types are proved to work for implicit feedback\n",
    "        Return: \n",
    "            model: lightfm model trained on training set\n",
    "            \n",
    "            return type: lightfm instance\n",
    "    '''\n",
    "    if model_type == 'bpr':\n",
    "        model = LightFM(loss='bpr', no_components=rank, user_alpha=regParam)\n",
    "        \n",
    "    else:    \n",
    "        model = LightFM(loss='warp', no_components=rank, user_alpha=regParam)\n",
    "\n",
    "    model = model.fit(interactions=train, sample_weight=weights, epochs=maxIter, verbose=False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(train, test, train_weights, rank, regParam, maxIter, top, model_type):\n",
    "    \n",
    "    '''\n",
    "        Params:\n",
    "            train: training csr matrix in form of scipy.sparse.COOMatrix\n",
    "            test: test csr matrix in form of scipy_sparse_COOMatrix\n",
    "            rank: dimensionality of the feature latent embeddings\n",
    "            regParam: L2 penalty on user features\n",
    "            maxIter: number of epochs to run\n",
    "            top: number of top recommendations to evaluate on\n",
    "            model_type: 'warp' - Weighted Approximate-Rank Pairwise Loss \n",
    "                        'bpr' - Bayesian Personalised Ranking\n",
    "            \n",
    "        Return: \n",
    "            p_at_k: precision at k\n",
    "            time: time for train and evaluation\n",
    "    '''\n",
    "    print('Model with maxIter = {}, reg = {}, rank = {} complete'.format(maxIter,regParam,rank))\n",
    "    st = time()\n",
    "    \n",
    "    model = lightfm_train(train, rank, regParam, maxIter, model_type, train_weights)\n",
    "\n",
    "    t = round(time()-st, 5)\n",
    "    print('Time used:', t)\n",
    "    \n",
    "    p_at_k = precision_at_k(model, test, k=top).mean()\n",
    "    print('Precision at K:', p_at_k)\n",
    "    \n",
    "    return p_at_k, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_train = [0.001, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 0.1% of training file size\n",
      "Model with maxIter = 5, reg = 0.05, rank = 30 complete\n",
      "Precision at K: 0.0048457\n",
      "Time used: 783.18844\n",
      "Model with 1.0% of training file size\n",
      "Model with maxIter = 5, reg = 0.05, rank = 30 complete\n",
      "Precision at K: 0.0050727203\n",
      "Time used: 921.37655\n"
     ]
    }
   ],
   "source": [
    "for pct in percent_train:\n",
    "    print('Model with {}% of training file size'.format(100*pct))\n",
    "    sample_train = df_train.sample(False, pct).toPandas()\n",
    "    sample_train = sample_train.drop('__index_level_0__', axis = 1)\n",
    "    \n",
    "    if sample_train.isnull().values.any():\n",
    "        print('Check null values')\n",
    "    \n",
    "    sample_test = df_test.toPandas().drop('__index_level_0__', axis = 1)\n",
    "    interactions_train, weights_train, interactions_test, weights_test = preprocessing(sample_train, sample_test)\n",
    "    p_at_k, t = train_and_test(interactions_train, interactions_test, weights_train, rank=30, regParam=0.05, maxIter=5,\\\n",
    "                           top=500, model_type='warp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 5.0% of training file size\n",
      "Model with maxIter = 5, reg = 0.05, rank = 30 complete\n",
      "Precision at K: 0.0051004402\n",
      "Time used: 1313.00878\n",
      "Model with 10.0% of training file size\n"
     ]
    }
   ],
   "source": [
    "percent_train = [0.05]\n",
    "for pct in percent_train:\n",
    "    print('Model with {}% of training file size'.format(100*pct))\n",
    "    sample_train = df_train.sample(False, pct).toPandas()\n",
    "    sample_train = sample_train.drop('__index_level_0__', axis = 1)\n",
    "    \n",
    "    if sample_train.isnull().values.any():\n",
    "        print('Check null values')\n",
    "    \n",
    "    sample_test = df_test.toPandas().drop('__index_level_0__', axis = 1)\n",
    "    interactions_train, weights_train, interactions_test, weights_test = preprocessing(sample_train, sample_test)\n",
    "    p_at_k, t = train_and_test(interactions_train, interactions_test, weights_train, rank=30, regParam=0.05, maxIter=5,\\\n",
    "                           top=500, model_type='warp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 10.0% of training file size\n",
      "Model with maxIter = 5, reg = 0.05, rank = 30 complete\n",
      "Precision at K: 0.00508876\n",
      "Time used: 1454.60265\n"
     ]
    }
   ],
   "source": [
    "percent_train = [0.1]\n",
    "for pct in percent_train:\n",
    "    print('Model with {}% of training file size'.format(100*pct))\n",
    "    sample_train = df_train.sample(False, pct).toPandas()\n",
    "    sample_train = sample_train.drop('__index_level_0__', axis = 1)\n",
    "    \n",
    "    if sample_train.isnull().values.any():\n",
    "        print('Check null values')\n",
    "    \n",
    "    sample_test = df_test.toPandas().drop('__index_level_0__', axis = 1)\n",
    "    interactions_train, weights_train, interactions_test, weights_test = preprocessing(sample_train, sample_test)\n",
    "    p_at_k, t = train_and_test(interactions_train, interactions_test, weights_train, rank=30, regParam=0.05, maxIter=5,\\\n",
    "                           top=500, model_type='warp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use validation set, with weights, maxIter=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_train = [0.001, 0.005, 0.01, 0.05, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 0.1% of training file size\n",
      "Model with maxIter = 1, reg = 0.05, rank = 150 complete\n",
      "Time used: 0.60603\n",
      "Precision at K: 0.0046532\n",
      "Model with 0.5% of training file size\n",
      "Model with maxIter = 1, reg = 0.05, rank = 150 complete\n",
      "Time used: 3.04343\n",
      "Precision at K: 0.0048607998\n",
      "Model with 1.0% of training file size\n",
      "Model with maxIter = 1, reg = 0.05, rank = 150 complete\n",
      "Time used: 6.72171\n",
      "Precision at K: 0.0049933996\n",
      "Model with 5.0% of training file size\n",
      "Model with maxIter = 1, reg = 0.05, rank = 150 complete\n",
      "Time used: 40.43237\n",
      "Precision at K: 0.0050335997\n",
      "Model with 10.0% of training file size\n",
      "Model with maxIter = 1, reg = 0.05, rank = 150 complete\n",
      "Time used: 78.69662\n",
      "Precision at K: 0.00505\n",
      "Model with 20.0% of training file size\n",
      "Model with maxIter = 1, reg = 0.05, rank = 150 complete\n"
     ]
    }
   ],
   "source": [
    "for pct in percent_train:\n",
    "    print('Model with {}% of training file size'.format(100*pct))\n",
    "    sample_train = df_train.sample(False, pct).toPandas()\n",
    "    sample_train = sample_train.drop('__index_level_0__', axis = 1)\n",
    "    \n",
    "    if sample_train.isnull().values.any():\n",
    "        print('Check null values')\n",
    "    \n",
    "    sample_test = df_val.toPandas().drop('__index_level_0__', axis = 1)\n",
    "    interactions_train, weights_train, interactions_test, weights_test = preprocessing(sample_train, sample_test)\n",
    "    p_at_k, t = train_and_test(interactions_train, interactions_test, weights_train, rank=150, regParam=0.05, maxIter=1,\\\n",
    "                           top=500, model_type='warp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 15.0% of training file size\n",
      "Model with maxIter = 1, reg = 0.05, rank = 150 complete\n",
      "Time used: 114.18631\n",
      "Precision at K: 0.0050488\n"
     ]
    }
   ],
   "source": [
    "percent_train = [0.15]\n",
    "for pct in percent_train:\n",
    "    print('Model with {}% of training file size'.format(100*pct))\n",
    "    sample_train = df_train.sample(False, pct).toPandas()\n",
    "    sample_train = sample_train.drop('__index_level_0__', axis = 1)\n",
    "    \n",
    "    if sample_train.isnull().values.any():\n",
    "        print('Check null values')\n",
    "    \n",
    "    sample_test = df_val.toPandas().drop('__index_level_0__', axis = 1)\n",
    "    interactions_train, weights_train, interactions_test, weights_test = preprocessing(sample_train, sample_test)\n",
    "    p_at_k, t = train_and_test(interactions_train, interactions_test, weights_train, rank=150, regParam=0.05, maxIter=1,\\\n",
    "                           top=500, model_type='warp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use validation set, maxiter=10, with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_train = [0.001, 0.01, 0.05, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 0.1% of training file size\n",
      "Model with maxIter = 10, reg = 0.05, rank = 150 complete\n",
      "Precision at K: 0.0047962\n",
      "Time used: 66.97906\n",
      "Model with 1.0% of training file size\n",
      "Model with maxIter = 10, reg = 0.05, rank = 150 complete\n",
      "Precision at K: 0.0050112004\n",
      "Time used: 174.51249\n",
      "Model with 5.0% of training file size\n",
      "Model with maxIter = 10, reg = 0.05, rank = 150 complete\n",
      "Precision at K: 0.005011\n",
      "Time used: 459.85961\n",
      "Model with 10.0% of training file size\n"
     ]
    }
   ],
   "source": [
    "for pct in percent_train:\n",
    "    print('Model with {}% of training file size'.format(100*pct))\n",
    "    sample_train = df_train.sample(False, pct).toPandas()\n",
    "    sample_train = sample_train.drop('__index_level_0__', axis = 1)\n",
    "    \n",
    "    if sample_train.isnull().values.any():\n",
    "        print('Check null values')\n",
    "    \n",
    "    sample_test = df_val.toPandas().drop('__index_level_0__', axis = 1)\n",
    "    interactions_train, weights_train, interactions_test, weights_test = preprocessing(sample_train, sample_test)\n",
    "    p_at_k, t = train_and_test(interactions_train, interactions_test, weights_train, rank=150, regParam=0.05, maxIter=10,\\\n",
    "                           top=500, model_type='warp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 20% of training file size\n"
     ]
    }
   ],
   "source": [
    "percent_train = 0.2\n",
    "print('Model with {}% of training file size'.format(20))\n",
    "sample_train = df_train.sample(False, percent_train).toPandas()\n",
    "sample_train = sample_train.drop('__index_level_0__', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095030,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train['user_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_train.isnull().values.any():\n",
    "    print('Check null values')\n",
    "    \n",
    "sample_test = df_val.toPandas().drop('__index_level_0__', axis = 1)\n",
    "interactions_train, weights_train, interactions_test, weights_test = preprocessing(sample_train, sample_test)\n",
    "#p_at_k, t = train_and_test(interactions_train, interactions_test, weights_train, rank=150, regParam=0.05, maxIter=10,\\\n",
    "#                           top=500, model_type='warp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
